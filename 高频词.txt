{"1632947816114552832": ["对天猫用户的用户行为：浏览、购买、收藏、加购物车从时间维度上进行分析，建立可视化图标分析数据特征，并建立模型对用户流失的可能行进行预测，分析不同用户的留存的概率，设定不同的方案增加不同类型用户留存的概率。", "对百货商场用户不同的购买数据，对用户进行分类，分析不同用户的购买情况，设定对应的方案增加用户的购买概率。 ", "搭建数据库存储用户的数据，分别从用户、商家和订单数据建立不同的库来储存数据。 ", "1.\t数据库分析与数据储存：\n数据库基本操作，O2O优惠券特征处理，外卖系统搭建\n\n2.\tpython基础和数据分析：\n     python语法，numpy和pandas库数据分析\n3.\t数据可视化：\n     Matplotlib、seaborn、pyecharts、excel、powerbi\n     汽车投诉数据采集策略、销售数据可视化\n4.\t数据采集：\n      Request、selenium、scrapy\n      招聘信息采集分析、B站视频分析和弹幕采集、图片音频视频、B站视频采集\n5.\t数据挖掘：\n      机器学习分类与回归：线性回归、逻辑回归、决策树、支持向量机\n      聚类：聚类概述和Kmeans、ap聚类\n      运营商流失用户分析与预测、天猫用户重复购买预测、百货商场用户聚类\n      文本挖掘：新闻文本分类与聚类、智慧政务文本分类、热点聚类\n6.\t深度学习：\n      BP神经网络、卷积神经网络、循环神经网络、长短时间记忆网络\n7.\t人工智能算法与实战：\n       OpenCV\n       马铃薯患病识别，人脸识别、基于深度学习的政务留言文本\n8.\tLinux、hadoo，HDFS、pyspark"]}
{"1630105867208753152": [null]}
{"1634019092572798976": null}
{"1635610357617786880": null}
{"1574625077318778880": ["本项目是基于Python-Flask框架搭建的员工管理平台，使用Bootstrap+Ajax+JavaScript构建前端 界面与接口交互并使用Jinja2模板引擎渲染HTML文件，使用Vue框架搭建后台管理系统，采用Python 作为开发语言设计并编程实现登陆注册、课程模块、考核模块、学员管理模块功能，利用Mysql实现对 数据的存储，最后使用阿里云服务器+Nginx+Uwsgi+Flask部署上线运行。", "该系统通过电化学方法电解产生羟基自由基(·OH)，羟基自由基(·OH)迅速氧化废水里的有机物羟基自由基(·OH)，水中有机物被羟基氧化时， 工作电极上将有电流变化,电流的变化与水中COD值成比例关系，通过计算电流的变化，便可测出水中COD的含量。该项目目前在中国贵州省遵义市茅台镇部分酒厂污水处理厂进行装置试部署，已成功试点安装并应用于工厂与污水处理厂，取得良好的经济效益。", "该项目是一个小型的Hadoop大数据处理和分析系统，系统采用Flume采集Web埋点产生的日志数据， 使用Map Reduce对数据进行清洗并下沉至Hdfs建立 Hive数据仓库，针对具体业务和维度进行数据仓 库的建模，最终通过Sqoop将结果数据写入Mysql数据库。", null]}
{"1584881617820844032": [null]}
{"1529487074560966656": [null]}
{"1530030540420415488": ["● 培训：参加国赛2个月培训，学习数模知识、数据预处理、图形可视化分析\n● 实践：利用层次分析法，对企业的利润、增值税等指标进行权重计算，建立多元线性回归模型，预测企业信誉得分与等级划分，确定是否给予企业贷款，数据报告最终以论文《中小型企业的信贷决策规划》呈现。\n", "在学院的组织下，参与本次python基础课程培训，掌握了python基本语句以及数据处理的可视化呈现。", "● 工作职责：负责统计数学系全院共1000多名学生的健康打卡、获奖情况、贫困核对等20+项学生相关表格；负责在同级的班群传达重要信息，累计汇总和统计各班的学生活动文件数500+。\n● 成果：获得学院老师的肯定，于2021年9月获得“优秀学生助理”称号。\n"]}
{"1506565365747023872": ["使用python中的BeautifulSoup、requests对去哪儿网进行爬取数据，再利用pandas对去哪儿网址数据的缺失值、重复值进行处理，通过matplotlit对分析处理的结果进行绘图； ", "通过power bi对现有的母婴、日化、食品、酒饮等数据文本进行合并，对数据进行一定的预处理，缺失值，重复值等进行删除，在对现有的数据筛选出电商还分销，对日期进行提取年、月、季。在对处理过后的数据进行可视化操作，绘制条形图、折线图等，再添加切片器对数据筛选。", "在培训中知晓了power bi的方便简洁和excel的使用", "简历"]}
{"1632286586903330816": null}
{"1630852451164880896": ["所用知识: 时间序列分解、 LSTM 模型、突变检测\n开发环境:Python3.8、 Pytorch、 Excel\n实现功能： 读取 excel 文件数据， 将数据划分为工作日与非工作日，采用时间序列分别对两类数据日用电数据进行加法分解， 使用 pytorch 框架搭建 LSTM 模型对两种情况分别进行预测，得到整个时间窗口的最大与最小用电负荷；再对结果进行时间序列减法得到每天间隔 15 分钟的间隔数据，综合分析?2 指数达到 0.83， MPE 指数达到0.056。", "所用知识: 子查询、 表连接、事件以及触发器\n开发环境: MySql、 Navicat Premium 12\n实现功能：通过使用触发器和事件实现交易的自动化变更，将客户在对商品的一系列下单操作行为，连接到商家获取订单商品信息，实现以商品为媒介，将客户与商家进行一对一对接，解决信息实时性的问题。 最后利用的子查询及表连接， 分别为客户和商家提供整理好的订单交易数据。", "所用知识： Pandas、 RFM 模型、 Kmeans 聚类、 Matplotlib\n开发环境: Python3.8\n项目过程： 首先对数据集 65535 条样本探索，对异常值处理并对特征单位进行统一，得到 59419 条数据； 根据 RFM模型搭建业务需求特征： 历史信用风险、经济风险和收入风险， 然后构建 Kmeans 聚类模型， 对客户进行风险等级划分， 绘制雷达图，针对不同等级客户提出相应风控意见。", "进行数据分析行业相关知识进修以及实训，主要内容包括：\nPython 基础知识实训； Matplotlib、 Seaborn、 Pyecharts 等数据可视化库实训\nXpath、 Json、 Selenium 等数据采集库实训； MySql 数据库实训\n数据挖掘回归与分类算法实训； Tensorflow 框架的 BP、 CNN、 RNN 算法实训\nLinux、 Hadoop、 Hive、 pySpark 等大数据技术基础环境实训", "潘伟华简历"]}
{"1631126636327993344": ["所用知识：时间序列分解、 LSTM 模型、突变检测\n开发环境：Python3.8、 Pytorch、 Excel\n实现功能：读取 excel 文件数据， 将数据划分为工作日与非工作日，采用时间序列分别对两类数据日用电数据进行加法分解， 使用 pytorch 框架搭建 LSTM 模型对两种情况分别进行预测，得到整个时间窗口的最大与最小用电负荷；再对结果进行时间序列减法得到每天间隔 15 分钟的间隔数据，综合分析?2 指数达到 0.83， MPE 指数达到0.056。", "所用知识: 子查询、 表连接、事件以及触发器 \n开发环境: MySql、 Navicat Premium 12 \n实现功能：通过使用触发器和事件实现交易的自动化变更，将客户在对商品的一系列下单操作行为，连接到商家获取订单商品信息，实现以商品为媒介，将客户与商家进行一对一对接，解决信息实时性的问题。 最后利用的子查询及表连接， 分别为客户和商家提供整理好的订单交易数据。", "所用知识： Pandas、 RFM 模型、 Kmeans 聚类、 Matplotlib 开发环境: Python3.8 项目过程： 首先对数据集 65535 条样本探索，对异常值处理并对特征单位进行统一，得到 59419 条数据； 根据 RFM模型搭建业务需求特征： 历史信用风险、经济风险和收入风险， 然后构建 Kmeans 聚类模型， 对客户进行风险等级划分， 绘制雷达图，针对不同等级客户提出相应风控意见", "培训机构：广东泰迪智能科技股份有限公司\n\n培训描述：进行数据分析行业相关知识进修以及实训，主要内容包括： Python 基础知识实训； Matplotlib、 Seaborn、 Pyecharts 等数据可视化库实训 Xpath、 Json、 Selenium 等数据采集库实训； MySql 数据库实训 数据挖掘回归与分类算法实训； Tensorflow 框架的 BP、 CNN、 RNN 算法实训 Linux、 Hadoop、 Hive、 pySpark 等大数据技术基础环境实训", null]}
{"1554782002648055808": [null]}
{"1569514123790778368": ["参与了“人脸图像口罩检测”项目，能够将理论知识结合分析工具灵活运用到项目工作中\n完成所有公司安排的项目任务"]}
{"1583024721031725056": ["利用python语言对数据进行处理，进行了汽车销售数据可视化分析，O2O优惠券使用预测，垃圾短信分类等模型建立与分析"]}
{"1623885034161307648": ["田昕钰简历，请您过目"]}
{"1503675724379324416": ["1 背景：随着互联网的快速发展，网络黑产特别是色情导流也日益增多，给用户带来了极大的伤害。色情导流用户发布色情/低俗内容吸引用户，并且通过二维码、联系方式、短网址等完成导流。大赛由字节跳动安全中心联合清华大学发起，参赛队伍需要通过数据挖掘的技术和机器学习的算法，针对题目要求，输出结果，同时，希望参赛队伍能通过本次比赛，挖掘数据背后潜在的意义，用算法的力量为用户提供优质体验。\n2 个人职责：代码编写、技术文档总结、方案PPT和现场答辩\n3主要使用工具包：sklearn、pandas、numpy、lightgbm、matplotlib、gemsim", "色情导流识别，二分类问题，个人赛，排名6/128", "疾病预测，二分类问题，团队赛，排名11/101", "欺诈识别，二分类问题，个人赛，排名45%/327"]}
{"1599636587363303424": ["主要使用 MySQL 数据库对得到数据进行增删查改等操作,进行了商品销售情况分析,以及构造 RFM 模型需要用到的表格,之后将表格综合起来,进行 RFM 模型的构建,做出基于 RFM 模型的用户", "帮助上级完成数据分析任务"]}
{"1529093815066034176": ["那是我第一门接触到的比较系统的学习到的编程语言。在这次培训中我学习到了python的基础知识和语法"]}
{"1461648125990141952": null}
{"1627308899029876736": [null, null, null]}
{"1562334736783900672": null}
{"1469173034668654592": ["通过图像处理技术和构建深度学习算法，以OpenCV 和深度学习算法为核心，设计出有效的模\n型实现识别岩石样本的岩性类别以及岩石含油面积百分含量。", "1、基础python数据分析挖掘\n2、深度学习、tensorflow\n3、此基础上自学pytorch", "1、官网创建的课程、线下班级管理\n2、协助资源研发\n3、对研发的资源进行录制讲解视频"]}
{"1631284316023685120": [null]}
{"1511539161700630528": null}
{"1630884821167374336": ["项目简介：跟随网络电商发展策略，用专业的数据进行理性分析，在合适的时机做正确的事，让店铺运营少走弯路，减少运营的试错成本。提供分析与可视化结果，比如注册量，留存率、注册-活跃-购买的转化率、游戏用户的价值分析等。\n项目岗位：数据分析\n项目职责：数据存储、数据清洗、统计以日、月为单位的人数点击量、访问量等、客户价值分群结果、用户流失的预警", "项目简介：获取了自己喜爱的花西子品牌下的散粉评论数据，进行自然语言识别，给不同类型商品进行评分分析与可视化，挑选出受欢迎的款式。\n项目职责：\n1.?? 评论数据获取；2.?? 评论数据预处理；3.?? 评分数据分析；4.?? 撰写分析报告", null, "岗位职能：数据储存、数据可视化、数据采集、数据挖掘、人工智能算法、Linux等\n学习工具：MySQL、Numpy、Pandas、Matplotlib等可视化、Selenium,scrapy框架、朴素贝叶斯等分类回归、K-Means等聚类、深度学习TensorFlow、Linux Vi、Hadoop等等", null]}
{"1631491020585828352": ["项目概述：肥料是农业生产中一种重要的生产资料，其生产销售必须遵循《肥料登记管理办法》，依法在农业行政管理部门\n进行登记。对所登记肥料进行相关分析\n项目主要目标：\n1. 对肥料登记数据进行预处理。\n2. 根据养分的百分比对肥料产品进行细分。\n3. 从省份、日期、生产商、肥料构成等维度对肥料登记数据进行对比分析。\n4. 对非结构化数据进行结构化处理。\n", "项目概述：为了更好地了解公司的销售情况，采用产品的销售额和利润数据，对其盈利能力进行分析和预测，给决策人员提\n供分析报告，以便为非洲各国提供更好的产品销售策略和服务。\n项目目标：1. 统计产品在当地的销售数据，预测未来销售情况。\n2. 设计可视化数字大屏，展示产品的销售情况，分析产品的盈利能力。", "复杂多变的气象条件和社会事件等不确定因素都会对电力系统负荷造成一定的影响，使得传统负荷预测模型的应用存在一定\n的局限性。同时，随着电力系统负荷结构的多元化，也使得模型应用的效果有所降低，因此电力系统负荷预测问题亟待进一\n步研究。\n项目主要目标：\n1．基于 LSTM 模型对地区负荷的中短期预测分析\n根据所提供的某地区电网间隔15分钟的负荷数据，建立中短期负荷预测模型\n2．基于 LSTM 模型对行业负荷的中期预测分析\n根据提供的各行业每天用电负荷相关数据预测行业未来3个月日负荷最大值和最小值。", "客户忠诚度主要体现为客户的行为和态度。客户行为主要表现为产品重复购买的频率，而客户态度主要表现为情感的倾向。为了有效挖掘客户忠诚度，需要从短期客户产品购买数据和长期客户资源信息中分析客户需求指标。其中，短期客户忠诚度分析是通过产品的购买数据，分析不同指标客户对银行产品的购买依赖度从而提供更好的销售服务；长期客户忠诚度分析则是从客户资源信息数据中挖掘客户流失因素、预测可能流失的客户，尽可能留住高价值客户。", "客户忠诚度主要体现为客户的行为和态度。客户行为主要表现为产品重复购买的频率，而客户态度主要表现为情感的倾向。为了有效挖掘客户忠诚度，需要从短期客户产品购买数据和长期客户资源信息中分析客户需求指标。其中，短期客户忠诚度分析是通过产品的购买数据，分析不同指标客户对银行产品的购买依赖度从而提供更好的销售服务；长期客户忠诚度分析则是从客户资源信息数据中挖掘客户流失因素、预测可能流失的客户，尽可能留住高价值客户。", "通过构建轻量级网络，使用迁移学习，减少训练时间，完成模型训练。通过 opencv 中的 haar 捕抓人脸，并对捕抓结果进行实时预测。", "完成多个实训项目：\n1.MySQL 电商营销用户行为数据分析\n2. MySQL 外卖系统搭建\n3. Python 共享单车使用量综合分析\n4. Python 教育平台的线上课程智能推荐策略\n5. Python 信用卡高风险用户识别\n6. Python 天猫用户重复购买预测\n7. Python 《长津湖》影评采集与分析\n8. Python 成都二手房可视化分析\n"]}
{"1503692152226578432": null}
{"1631135062105915392": ["所用知识：时间序列分解、 LSTM 模型、突变检测 开发环境：Python3.8、 Pytorch、 Excel 实现功能：读取 excel 文件数据， 将数据划分为工作日与非工作日，采用时间序列分别对两类数据日用电数据进行加法分解， 使用 pytorch 框架搭建 LSTM 模型对两种情况分别进行预测，得到整个时间窗口的最大与最小用电负荷；再对结果进行时间序列减法得到每天间隔 15 分钟的间隔数据，综合分析?2 指数达到 0.83， MPE 指数达到0.056。", "所用知识: 子查询、 表连接、事件以及触发器 开发环境: MySql、 Navicat Premium 12 实现功能：通过使用触发器和事件实现交易的自动化变更，将客户在对商品的一系列下单操作行为，连接到商家获取订单商品信息，实现以商品为媒介，将客户与商家进行一对一对接，解决信息实时性的问题。 最后利用的子查询及表连接， 分别为客户和商家提供整理好的订单交易数据。", "所用知识： Pandas、 RFM 模型、 Kmeans 聚类、 Matplotlib 开发环境: Python3.8 项目过程： 首先对数据集 65535 条样本探索，对异常值处理并对特征单位进行统一，得到 59419 条数据； 根据 RFM模型搭建业务需求特征： 历史信用风险、经济风险和收入风险， 然后构建 Kmeans 聚类模型， 对客户进行风险等级划分， 绘制雷达图，针对不同等级客户提出相应风控意见", "广东泰迪智能科技股份有限公司 培训描述：进行数据分析行业相关知识进修以及实训，主要内容包括： Python 基础知识实训； Matplotlib、 Seaborn、 Pyecharts 等数据可视化库实训 Xpath、 Json、 Selenium 等数据采集库实训； MySql 数据库实训 数据挖掘回归与分类算法实训； Tensorflow 框架的 BP、 CNN、 RNN 算法实训 Linux、 Hadoop、 Hive、 pySpark 等大数据技术基础环境实训", null]}
{"1484409030448381952": null}
{"1502923771693105152": null}
{"1541793867911790592": ["和同学一起开发一款校园综合平台小程序，包括校园二手市场交易、商品的发布交易、校园的简介、课表查询等功能，该小程序使用云开发完成，本人负责小程序前端页面的制作。", "（暑假实习）负责公司游戏小程序的开发，负责游戏分成比例部分前端部分，了解相关分成比例的逻辑后，负责游戏申请游戏、游戏详情、添加下线页面的部分代码。\n负责企业官网的开发，从搭建到开发，采用vue.is框架，使用vuecli,,vue-router,和element ui 库，vant ui 库等开发企业目标管理官网，配合ui 进行页面的设计、布局、适配、优化。\n", "负责商城项目内管端部分页面的开发，采用公司基于element ui的框架，开发商城系统-商品管理，营销系统-任务广场页面，然后与后端进行联调。\n负责商城项目app端商品详情部分页面的制作，采用vue和Nut ui 进行开发，使用easy2api进行接口的调试，与后端讨论接口。\n"]}
{"1582598236647063552": ["针对某地区的新零售无人智能售货机的销售数据进行分析，项目的流程主要有数据预处理 → 数据分析 → 搭建销售额回归模型 →销售额预测", "基于贷款者的身份信息预测贷款者是否存在违约的可能性，项目的流程主要有数据预处理 → 数据分析 → 搭建分类模型 → 预测", "该项目是通过害虫发光诱捕平台诱杀各类趋光性害虫，同时实时的对装置进行拍摄识别害虫的种类和统计某时刻的数量，实现项目的技术栈主要有Python、目标检测算法等", "学习机器学习算法、深度学习算法、数据分析可视化等内容，参与到热门电影短评数据爬取与分析、基于tensorflow的人脸识别、新零售无人智能售货机商务数据分析等项目的实战。", "学习Pandas、Numpy等库的高阶用法、网络爬虫、数据可视化、Mysql、机器学习算法、深度学习算法、Linux命令、大数据开发技术，参与到校园供水系统智能管理、外卖数据库系统制作与数据分析、疫情期间网民情绪识别、教育平台的线上课程智能推荐策略、 天猫重复购买预测等项目的实战。", "GPA3.96/5.0，专业排名前1%"]}
{"1524204652525125632": null}
{"1507237125567938560": null}
{"1461659304984707072": ["大数据开发培训，学习了大数据相关课程。例如：Linux操作系统、SQL基础、Java设计、Hadoop、Hive、Zookeeper、HBase、Scala、Spark、Kafka、Flume、Flink。\n大数据项目案例，如：电子商务日志数据采集系统、热门博文实时更新"]}
{"1550096565136392192": ["学管师——定期向家长反馈学员的学习情况，解决家长、学员提出的问题；为学生制定科学的达分目标；整理归档学员基础信息、学情记录、教学服务质检等工作数据。", "运营助教——负责给计算机二级学员答疑解惑，解决学员学习遇到的问题。汇总整理学员常见问题，安排答疑时间。"]}
{"1461666278635864064": ["负责防洒模块和降温模块的设计，建立温度关于时间的微分方程，寻找降温材料最优配比", "Python机器学习算法与项目应用"]}
{"1461601893229920256": null}
{"1569987734318219264": ["掌握使用 python 的 requests 库实现花卉图片数据爬取 → 使用tensorflow库实现模型搭建 → 使用 Streamlit 前端完成可视化页面。", "构建口罩检测的深度学习模型 → 搭建口罩检测系统 → 调用摄像头人脸定位 → 调用摄像头实时检测人员是否佩戴口罩。", null, "? 负责接听客户电话，向客户系统详细的介绍公司的产品及服务；主要锻炼与人沟通交流和表达能力。\n? 通过电话确认客户购买信息，并详细记录；主要锻炼对产品的自我理解、向外推荐、信息登记等能力。", "? 接受 python 课程教学，主要学习数据挖掘、数据分析的理论内容与实践项目操作。\n? 作为小组长，带领小组实习生独立完成公司下发的项目任务。"]}
{"1630818546172952576": ["参加数据分析的学习实训，主要学习的内容有:\n?  Python：pandas、numpy等基础库；matplotlib、seaborn、pyecharts等可视化库；静态网页，动态网页的网络爬取。\n?  项目实训：2018年泰迪杯数据分析职业技能大赛B题数据可视化，爬取豆瓣电影短评数据和可视化分析\n?  Mysgl：数据库的增删改查，子查询，虚拟表，存储过程，窗口函数，存储函数，触发器和事件。\n?  项目实训：mysql 外卖系统数据分析、电商营销数据分析\n?  机器学习：回归、分类、决策树与支持向量机、朴素贝叶斯、KMeans 聚类、随机森林、梯度提升树特征选择、关联规则、智能推荐。\n?  项目实训：教育平台的线上课程智能推荐、天猫用户重复购买预测、共享单车使用量综合分析\n?  深度学习：BP 神经网络、CNN、RNN 、自然语言处理、计算机视觉\n?  项目实训：手写数字识别、花卉识别、疫情期间网民情绪识别。\n", null]}
??法，将算法运用到样本图片中，以完成火灾的快速识别。接着，采用CNN神经网络对火灾火焰进行识别得到模型得到更准确的预测效果。\n项目职责：1.搭建项目框架；2.编写代码实现项目；3.编写项目文档（论文）；4、制作汇报PPT并进行汇报。", "在为期长达四个月的培训中，主要运用Python以及MySQL 数据库进行综合项目实战，将所学知识运用于实际项目中。\n主修课程：Python（数据分析与应用、数据可视化、网络爬虫、机器学习、综合项目实战）、深度学习原理及编程实现、自然语言处理及项目实战、MySQL 数据库及项目实战、Linux 基础、hadoop、hive、spark", null]}
{"1501850256562847744": null}
{"1498147738557218816": ["培训过程中掌握了很多相关操作，且对自己掌握的知识很满足"]}
{"1579833809761861632": ["1 对客户数据进行预处理，并对字符型数据进行特征编码。\n2 基于短期客户产品购买数据，分析不同指标客户对银行产品的购买依 赖度，并进行可视化呈现。\n3 基于长期客户资源信息数据，分析客户流失因素，并进行可视化呈现。\n4 依据长期客户资源信息数据的分析结果构建相关指标，对银行客户长 期忠诚度进行预测。", "人工智能方面的技术支持，包括软件安装、理论知识和课程内容等答疑工作。", "简历"]}
{"1516604454231736320": null}
{"1461530285551255552": ["负责线上产品策划"]}
{"1523993408442597376": null}
{"1461663453243637760": ["1、安排智能工作室成员的课程学习进度与项目进度；\n2、与泰迪公司沟通，传达公司对工作室的管理及安排。"]}
{"1573938917198135296": ["使用Java语言进行系统代码的编写，数据库使用JDBC进行连接。\n项目结构分为表示层，业务层，数据访问层；表示层展示窗口与用户进行交互，业务层用于实现业务逻辑，数据访问层DAO层中封装了实体类以及对数据库的增删改查操作；页面的编写使用到了Java的GUI，同时添加了Swing中的鼠标事件、键盘事件等。\n主要负责系统页面以及登录，考勤管理，员工管理，工资绩效，系统管理等功能的代码编写。", "该系统采用Flume采集日志数据到HDFS，同时，使用Sqoop采集Mysql数据库中的业务数据到HDFS；使用MapReduce进行数据清洗，并下沉至Hive数据仓库中；使用Spark进行分类预测，以Java WEB框架作为底层的应用开发框架，通过Spring DATA JPA将数据的分析结果保存在MySQL中，最后使用ECharts实现可视化。\n\n", null]}
{"1502226049910571008": null}
{"1500714639468658688": null}
{"1496340730497597440": [null]}
{"1614575985309646848": null}
{"1498246507764252672": ["这是一个小米、boss直聘及京东静态页面，主要负责前端页面设计：\n● 使用html编写小米官网的页面及京东页面\n● 利用css优化界面\n● 引用阿里巴巴矢量标图标库图\n 最终能完美展现出与官网一致的页面", "这是一个小程序，结合前后端，主要负责前后端：\n● 数据库创建表\n● 服务端利用mybaits编写增删改查\n● 前端编写利用html,结合css样式编写登录及注册页面，管理员页面，留言板，相册\n● 使用html写出基本框架\n● 引入bootstrop、js库进行响应式布局\n● 动静态结合", "这是一个电商系统，由前后端结合，\n主要负责前端、管理员及用户登录注册，管理员后台对用户的基本信息进行增、删、查、改，用户实现购买商品的基本操作，对个人信息进行修改：\n● 使用html写出基本框架\n● 利用css样式优化页面，element简化页面\n● 引入bootstrop、js库进行响应式布局\n● 动静态结合\n● 引用阿里巴巴矢标图"]}
{"1501939246758494208": ["以广州市本田二手汽车为数据，进行特征筛选出影响价格的指标，建立预测模型，为二手车交易市场提供好的价格指导。\n1.将数据划分特征和标签，对特征进行 one-hot 编码，再对数据进行标准化 StandardScaler。\n2.（1）划分训练集和测试集，调用随机森林和梯度提升回归模型预测，选用 MSE、MAE、R2_score 三种评价\n指标判别模型准确度。（2）对梯度提升回归模型进行调参，如调整学习率、学习算法的数量等优化模型。\n3.分析结果，为消费者提供合理价", "根据所给销售记录表、产品名称表、商店名称表、销售渠道表等，进行多维度透视表分析\n"]}
{"1461614384609624064": null}
{"1476408366162116608": null}
{"1470329852602220544": ["使用OpenCv等模块库进行图像处理。利用深度学习构建残差网络模型ResNet101进行识别分类训练，获得样本岩石岩性识别的准确率。利用Grabcut算法101提取图片，再使用二值化将图片转换颜色，最后使用HSV方法提取图片颜色像素进行灰度化得到掩膜图片。根据黑白颜色面积求出含油面积百分含量。", "1.利用python完成网络爬虫实战，数据分析及应用可视化（天猫重复预测，线上课程智能推荐等项目）\n2. 熟悉数据库SQL基础，了解Linux,Hadoop,hive基础\n3. 熟悉python机器学习和视觉，深度学习原理及编程实现；掌握TensorFlow,pytorch框架\n（水质识别等项目）\n4.熟悉NLP自然语言处理涉及文本分类，文本情感分析，词频统计等（手机评论采集分析等项目）\n", "1.负责数英课程的备课和教学工作，提高学生学习兴趣，帮助提高成绩。        \n2.改善教学过程，定期与家长进行教学沟通，提高教学服务质量。\n", null]}
{"1471049670871613440": ["据统计，2020年，中国彩电市场零售额同比下降9.1%，零售规模同比下降11.7%。这一趋势在过去几年已经开始。电视机的销量在逐渐下降，整个行业也在下降。一方面，电视机的质量比较好。基本上，一个家庭购买一台电视机后，可以使用五六年，使用时间越长，可以使用十年以上。因此，市场对电视机的需求也有所下降\n使用ElasticSearch和Spark等工具对数据集进行分析。数据集主要包含了用户基本信息、收视信息、订单信息、账单信息和用户变更信息共5个数据文件，本案例基于上述的数据集，使用Logstash采集到ElasticSearch，用Spark读取ElasticSearch的数据，并且对数据进行初步探索以及对数据的预处理；把预处理后的数据再次存入Hive。SparkSQL构建用户画像并导出到csv文件，最后使用Spark MLlib构建SVM模型预测挽留用户。", "自1946年世界第一台电子计算机ENIAC研制成功后，在几十年中其迅速发展，成为了如今手中的手机，电脑等一系列电子产品，成为生活中无法剥离的一部分。在此背景下互联网也高速发展，两者结合引领了如今的大数据时代的到来。\n\n探索对象：2014年至2015年美国西雅图的售房信息，共计10000条数据、14个字段，其中包含了销售价格、房屋面积、结构及位置等信息。通过对现有信息进行实时抽取，模拟实时产生的无界数据。", "学习关系型数据库产品（SQL）进行数据库编程以及Spark，Hive，Hadoop，zookeeper，HBase，Flume，Kafka，ES等大数据开发技术，实操对应技术的案例，完成相关技术开发项目。", "协助班主任管理好学生，解决学生课上提出的问题，课后批改学生的作业，并写入成长手册。"]}
{"1468183620412899328": ["这个项目主要是用Python自然语言处理对380平台的盈利、销售情况等做出分析，评估该平台各行业的财务状况、健康状况和发展趋势。", "这个项目的目的是对疫情实时数据进行开发和分析，爬取网易新闻的疫情实时数据到本地，在Linux操作系统下将数据保存至HDFS，通过Spark SQL读取并高效分析处理全世界、全国的疫情数据，最后用Python对大数据进行可视化分析。"]}
{"1467797054184095744": ["通过使用 python爬虫爬取京东商品评论和爬取豆瓣电影评论，分别对获得的数据做\n可视化分析，分析消费者对商品和电影喜好的偏好程度。\n主要职责：\n1、使用 request库获取京东评论数据和豆瓣电影评论数据；\n2、使用 xpath解析网页并存储数据；\n3、对获得的数据做可视化分析，分析喜好的偏好程度。", "对餐饮企业而言，通过分析历史数据，得到营销手段，基本任务是从餐饮企业采\n集各类菜品销量、成本单价、会员消费、促销活动等内部数据建模分析，从而实现菜品智能\n推荐、客户价值分析、新店选点优化，热销、滞销菜品分析和销量趋势预测。\n主要职责：\n1，使用 python对数据进行预处理，统计餐饮菜品数据，进行可视化分析；\n2，使用 Apriori算法实现菜品的智能推荐，使用 K-Means算法进行客户价值分析，用决策树\n算法实现餐饮客户流失预测；\n3，对餐饮企业通过以上的统计分析与算法挖掘分析，并针对性地提出相关建议，以提高餐饮\n企业的经营收益。", "马铃薯病虫害诊断和防治问题给种植马铃薯的农民生产带来了巨大的挑战，主要\n问题如下：农业专家的离线问诊，存在时效性不高的问题；农业专家的在线问诊，存在着农\n民拍摄的图片专业度不高，影响了专家在线问诊判别木薯病虫害的精度。通过深度学习技术，\n识别出晚疫病、早疫病和马铃薯健康的叶子（共三类），让农民们能快速获知疾病类型，为\n及时减少损失提供参考。\n主要职责：\n1、使用 tensorflow读取数据，并对数据进行标准化，做数据增强；\n2、构建 CNN卷积神经网络，输入数据进行训练模型；\n3、得到训练好的模型，对新的样本进行识别预测。", "分析客户历史信用记录、经济情况、经济风险情况，对不同客户类别进行数据探\n索，对不同客户类别进行特征分析，比较不同客户的风险，构建 K-Means聚类模型评估该机\n构的信用卡业务风险，针对目前的情况提出风控建议。\n主要职责：\n1、对数据清洗、属性构造；\n2、构建 K-Means聚类模型，对信用卡客户进行风险分析；\n3、根据聚类模型得到的客户风险分类结果撰写报告。", "在广州泰迪智能科技股份有限公司的 python数据分析师就业班培训学习，对大数据挖掘技术有一定的理解和认识，培训内容如下：\n1、数据挖掘建模:回归、分类与预测、聚类分析、关联规则、时序模式、智能推荐等；\n2、深度学习算法:tensorflow神经网络、计算机视觉、NLP自然语言处理；\n3、大数据技能:Hadoop、Spark、ive、MySQL；\n4、python爬虫:基本css、xpath、beautifulsoup4、等页面解析语法，以及 selenium库和re库、ajax动态加载、基本js加密", null]}
{"1496330994284888064": null}
{"1470311341238648832": ["在hadoop集群liunx系统的hive库上对电信行业的5g套餐用户数据进行开发，提取有用的数据给数据分析人员分析，同时在值班的时候对数据入库进行监控，和专业运维人员沟通，做一些基础的运维工作。", "做大数据组件，比如kafka,flume,spark相关实时和离线数据处理项目。", "对电信行业上亿条海量数据进行开发，本人作为开发组的人员实时和数据分析人员进行沟通，且完成了5g专题项目。"]}
{"1493788610879684608": ["我的职责：负责完成学校大屏可视化分析、专业大屏可视化分析、数据管理和帐号管理页面\n涉及技术：vue、html、css、javascript、echarts、node、前后端交互"]}
{"1487239888775544832": null}
{"1495664524416647168": ["项目描述： 对于问题1，根据上市公司实施高送转的经济学意义，筛选对上市公司实施高送转的影响因子：股价、上市年限等基 本因子，每股未分配利润、每股资本公积等成长因子以及其他因子；针对上市公司所属行业对于高送转的影响进行分 析，并且在对数据进行清洗、预处理之后，运用相关分析、回归分析等数理统计方法筛选出对上市公司实施高送转方 案有较大影响的因子。 对于问题2，针对于建立高送转预测模型。首先，根据筛选出的因子数据，初步尝试构建BP神经网络模型和决策树并 进行预测。其次，在决策树模型的基础上深入探究：利用集成学习中的bagging、boosting以及随机森林三种方法建 立股票高送转的预测模型，并对比结果对最优的boosting模型进行优化。引入xgboost和GBM（梯度提升方法）来 进行最终模型的建立。 \n责任描述： 在项目中，本人负责对数据进行集成化处理等数据预处理操作，对部分影响因子进行分析与筛选，并应用 神经网络模型对目标标签进行训练与预测。", "项目描述： 2021.07 - 2021.08 汕头大学 统计学 | 本科 团支部书记 社团学生社团联合会社团资讯部干事 广东泰迪智能科技有限公司(大数据事业部) 数据分析师 O2O优惠券使用预测针对某平台线下真实消费行为构成的上百万条数据，使用python进行数据分析和数据可视化，利用神经网络、决策 树等算法建模并评估效果。经考核，完成所有项目任务，成绩优秀。 \n责任描述： 本人负责对项目进行分工，协助团队成员使用python进行数据分析、特征构建和数据可视化，主要完成利用神经网络、决策树等算法建模并评估效果的工作。", null]}
{"1468149322909614080": ["每天都很充实，可以说是提供了一个良好的平台给予我们很好的融入社会的节奏，面对难题团队处理能力，个人情绪问题上的及时释放等，也学习到了计算机编程方面的知识，使个人得以提升。", null]}
{"1480370431885180928": null}
{"1491717866792288256": null}
{"1462718849626537984": ["本项目通过采集用户购买商品信息、评论详情以及对应的评价，对数据进行预处理、用户偏好分析以及评价分析等。\n1.用户数据的爬取\n（1）爬虫爬取网页信息，逆向分析法获取带评论数据的URL网址；\n（2）利用正则表达式，提取商品型号等相关信息，以及用户对商品的评论信息；\n2.数据预处理\n（1）处理重复值；\n（2）处理一些没有价值的数据；\n3.对手机信息以及对应的用户评论进行数据分析。\n（1）绘制词云，展示评论（好中差评）关注的地方（jieba分词）；\n（2）分析商品随时间变化的销售情况、评论情况；用户对商品属性（如：颜色，内存等的偏好）\n", "本项目通过对数据进行数据分析、预处理；从处理后的数据中提取用户在共享单车的使用量，分析各个特征对其的影响，进行特征构造，以此搭建实现单车使用量的预测的线性回归模型。\n项目职责：\n1.\t数据探索、数据预处理、相关性分析；\n2.\t构建模型，进行预测；\n3.\t撰写分析报告。", "通过培训，掌握了大数据科学的基本理论、方法和技能，具备熟练的应用数据挖掘、数据分析技术解决大数据问题的能力，培养从事大数据分析和挖掘工作的能力。\n\n主修课程：\nPython（数据分析与应用、数据可视化、网络爬虫、机器学习、综合项目实战）、深度学习原理及编程实现、自然语言处理及项目实战、MySQL数据库及项目实战、Linux基础、hadoop、hive、spark"]}
{"1493072448155942912": ["分析指标：非挥发性酸、挥发性酸、密度、PH、酒精等\n分析工具：R，使用了nnet包\n分析过程：数据预处理：对数据进行清洗，利用class.ind函数对数据进行预处理；用summary函数对数据集进行描述分析并绘制柱状图，对数据进行归一化，设置随机种子数，建立神经网络模型\n", "分析指标：股票代码、实际披露时间、发布时间、报告截止日期、报告类型等\n分析工具：Excel、Python（主要使用pandas包和numpy包）\n分析过程：数据预处理：包括数据合并、缺失值处理、数据标准化；对数据进行整合，用Python建立逻辑回归、决策树、伯努利贝叶斯模型进行分析，确定出造假数据"]}
{"1490603291757903872": ["项目概述：\n从网上下载十九大的文件报告，并且根据人民日报的总结，提炼出了“建设”，“百年奋斗”，“新时代新思想”等关键词，将关键字存入数组，对于十九大报告按照句号分割，并且切割出的句子包含关键字，会将关键字传给一个临时变量，将临时变量通过io流传入一个txt文件，并且自动换行。对于提取了所有关键字的txt文件使用mapreduce进行词频统计处理。\n\n小组分工以及我的分工：\n我主要负责代码的撰写以及论文的撰写，并且在他人制作ppt的时候给予疑惑解答。小组成员主要负责文章查找，关键字挖掘，以及小组讨论展开，围绕着论文进行讨论，并且提出相对应的问题", "1：项目概括\n使用问卷调查的形式在多个班群中发布问卷调查，获得学生们对于期末考试形式的理想情况，并且将所获得的数据汇总到csv表格中，使用spark sql读取汇总的csv文件，并且对读取文件进行数据清洗，后根据清洗得到的数据进行分析，比如更喜欢一个人完成作品还是小组形式，如果是小组合作，所获得的分数是小组成员一致还是根据贡献给分等问题\n\n2：人员分工以及我的责任\n在小组中，我负责代码编写以及论文撰写的部分，别人也是负责发布问卷调查，对问卷调查进行汇总，PPT的制作已经上台演讲", null, "1：使用 SQL 语句对于数据进行清洗\n2：使用清洗后的数据进行报表\n3：按时按质完成自己培训时间内的培训内容", null]}
{"1484369311995920384": null}
{"1461606361627492352": null}
{"1469222105404014592": ["课外课题研究对象：潮州市陶瓷行业\n\n研究背景：进入21世纪以来，我国的陶瓷制造行业经历了一个稳定发展时期，陶瓷制品的产量和陶瓷行业企业数量都有了巨大的增长，我国的陶瓷总产量位居世界第一位，已成为世界上最大的陶瓷生产国和出口国，但陶瓷行业仍整体效率偏低，技术水平不高，缺乏品牌意识。潮州市拥有很多陶瓷生产企业，处于陶瓷行业生产的上游，潮州市生产的陶瓷质量上乘，但在全国缺乏知名度，没有形成知名品牌。\n\n研究内容为：对潮州市的陶瓷行业进行研究，通过数据分析，了解潮州的陶瓷行业当前发展状况，对潮州陶瓷行业的发展前景做分析和做出建设性建议。\n\n\n", "制作一个教学科研查询服务平台，给全校师生提供科研项目和论文的查询服务。\n\n韩山师范学院教学与科研信息查询与服务平台是基于教学与科研为目的开发的信息查询与服务平台，为了解决学校在信息化建设中的数据管理中数据不统一、应用不完善、部分服务不能满足当前业务需求等问题。本平台采用网页端形式，用户登录平台，可享受资料查询、文献查询、教学资源查询、教学进度管理、科研项目进度管理、科研项目协同合作等服务。", "负责赛题第二题的第二部分，对图像中的特定目标进行识别并计算其占比，最终获得国家三等奖和省三等奖。\n\n使用技术：使用Python、机器学习框架(pytorch)、OpenCV技术，运用cv2、numpy等科学技术库。\n\n赛题负责部分介绍:现有样本数据是采用工业相机在录井现场对岩屑和岩心样品进行拍照，分别在暗箱内拍摄白光和荧光两种相片，如赛题图 1和图 2所示。白光灯下拍摄的相片是用于提取颜色、纹理、粒度等特征识别岩性，荧光灯下拍摄的相片是用于识别含油气性（石油在紫外线照射下具有的发光特征，其中的绿色和黄色部分是含油的）。\n", "在广东泰迪科技进行针对 Java? Linux? Hadoop? Mysql? Zookeeper? HBase? Flink? Spark? Scala? Hive Kafka? Flume? Elasticsearch? 等开源大数据开发技术及组件的专业培训。", "社团活动：任职期间对工作认真负责，独立制作完成多份协会的各项宣传海报和宣传视频，获得很好的宣传效果；多次协助组织策划宣传举办大型活动及超过200人的晚会活动，负责宣传工作及晚会现场调控，协调各节目及表演人员的出场顺序，现场做到井然有序。既做到了活动举办前运筹帷幄也做到了活动举办时临危不乱。\n部门活动：每周课前备课，准备简单易懂的PS、PR课程内容，课间给部员上PS、PR课，教他们相关的宣传技能和传授宣传海报和宣传视频制作心得，课后布置小作业和做出点评。带领他们参加社团活动，加速他们融入社团，快速学习和成长。", "在学院办公室负责协助老师完成学院老师课程的安排和调整，文字处理和表格制作，整理数据和档案等办公室事务；协助老师管理实验室，负责学院实验室服务器管理和日常维护，搭建服务器实验环境。工作认真负责，待人礼貌，校对数据认真仔细，文件整理井然有序，未出现过任何纰漏，既减轻了老师的工作量也提高了老师的工作效率，是老师的得力小助手，获得了老师们的一致认可。", null]}
{"1475685768210022400": null}
{"1467792600214929408": ["项目介绍： 根据赛方提供的相关上市公司的财务数据，采用 Filter 过滤法、Lasso 回归等方法， LR、SVM、LightGBM 等机器学习算法处数据，拟合结果，筛选确定出各行业财务造假有关 的数据指标，并分析比较不同行业相关数据造假指标的异同。 \n项目职责： 数据预处理、参数调优、数据分析、撰写分析论文报告", "在此次培训经历中，学习的主要课程有Python编程基础、Python数据分析与应用、Python数据可视化、Python网络爬虫、Python机器学习、综合项目实战、深度学习原理及编程实现、计算机视觉及项目实战、自然语言处理及项目实战、MySQL数据库、MySQL数据库项目实战、Linux基础、Hadoop、hive、spark。"]}
{"1475688461037076480": null}
{"1483350550874554368": null}
{"1470313042016337920": ["综述目前国内外研究进展,进一步分析多模态磁共振的特征提取、特征选择、分类器模型等传统机器学习方法建立计算机辅助诊断模型的关键技术,并简要概述基于深度学习方法在早期帕金森病分类诊断中的应用。指出基于多模态磁共振图像,采用机器学习或深度学习方法构建计算机辅助诊断模型,能够客观、准确地识别帕金森患者,对提高早期帕金森诊断的准确性具有很大价值和应用前景。", "用Logstash采集广电的所有数据表并存储到ES，然后通过Spark读取ES上的数据，读取完后的格式为DataFrame，并将这些数据另存到Hive，减少IO和内存资源的损耗。\n读取到Hive上的数据后，对这些数据进行预处理，去除重复值和无效数据等，接着先进行数据的探索，以便更好的实现业务目标。\n然后是用Spark的DataFrame操作实现用户画像，并将多个用户画像结果保存到MySQL数据库，方便读取，然后用DataFrame的union方法实现多个用户画像的联结，接着应用Python的Flask插件实现每个用户的用户画像可视化展示。\n", "参加广州泰迪智能科技有限公司组织举办的为期5个月的“大数据开发技术及工程实践”培训及实训。通过此次实训，我对大数据开发技术有了更深刻的理解和认识。培训内容如下：\n1.学习Hadoop，hive，Hbase，spark，Kfaka，zookeeper，mySQL,Flume，ElasticSearch等大数据组件的搭建与基本操作\n2.语言学习:java，scala\n3.全真企业案例:1.图书评分实时分析系统 ?2.网络入侵自动识别 ?3.商品实时推荐 ? 4.P2P信用贷款风险预测", "推广app"]}
{"1468148406491938816": ["本人基于python语言对关于网球新闻的文本进行提取切分文本成句子，通过GloVe词向量提取句子词向量，文本预处理并用余弦相似度填充空的相似度矩阵，应用PageRank算法完成摘要提取，为网球爱好者提供更加精确的网球新闻。", "负责Excel，Word的编辑与导入内容；\n整理资料。", "锻炼了授课的能力；\n拥有一定的沟通能力与团队意识；\n规划学生的学习计划，寓教于乐。"]}
{"1480029519657172992": null}
{"1479721504424984576": null}
{"1466233482740105216": ["参加广州泰迪智能科技有限公司组织举办的为期 4 个月的“大数据挖掘技术及工程实践”培训及实训，主要学习的课程有 Java、Hadoop、MySQL、Hive、Spark、Scala、Flink 等。 "]}
{"1463685809768103936": ["python基础、基于matplotlib数据可视化、pandas基本使用、基于python的网络爬虫、基于sklearn机器学习（一小部分）、基于TensorFlow的深度学习（一小部分）、基于opencv的机器视觉、自然语言处理，MySQL", null]}
{"1468147138121826304": ["内容：利用Flume、Kafka、Spark Streaming等工具做一个简单的图书评分实时分析系统，\n\n实现四个需求：\n1、\t计算数据流中每个用户的平均评分 —>用户评分区间喜好；\n2、\t计算数据流中每本书籍的平均分 —>书籍的质量；\n3、\t统计数据流中用户、书籍的出现次数 —>用户的资历、书籍的销量；\n4、\t将以上结果合并为DataFrame并存入Hive中。\n", "1.\t大数据开发课程：\nHadoop生态圈内的主要组件（Hadoop、Hive、Hbase等），\n主流的实时采集（Flume、Kafka）、处理工具（Flink、SparkStreaming），\n分布式计算框架（Spark）\n"]}
{"1467789372454731776": ["根据游客对景区及酒店的网评文本，通过数据挖掘游客满意度来分析目的地美誉度高低，为旅游企业科学监管、资源优化配置以及市场持续开拓提供策略，包括基于Python中文自然语言处理的游客对景区及酒店印象分析、游客对景区及酒店的综合评价、游客网评文本的有效性分析、景区及酒店的特色分析。", "根据某教育平台近两年的运营数据，即教育平台的线上用户信息和学习信息，通过数据分析为教育平台和用户提供精准的课程推荐服务，包括分析平台用户的活跃情况，计算用户的流失率，以及分析线上课程的受欢迎程度，利用基于课程的协同过滤算法构建课程智能推荐模型，为教育平台的线上推荐服务提供策略。", "培训期间主要学习Python数据分析与应用、Python网络爬虫、Python机器学习、深度学习、计算机视觉、自然语言处理、MySQL数据库、Linux、hive、spark等，并结合对应案例进行实现。"]}
{"1485077856240402432": null}
{"1468155453379837952": ["在虚拟机定时产生模拟数据，用flume采集数据到kafka，再用Spark Streaming拉取kafka实时消费出来的数据去开发，分析出图书热度排行榜，再把结果存储到hive中\n所用到的专业技术：kafka、flume、Spark Streaming、hive\n项目流程：数据获取、数据处理、数据存储", "在这次培训中，我学到了很多实用的技能"]}
{"1470718882556805120": ["       在广州泰迪智能科技有限公司进行四个月的数据分析挖掘实习，学习了大量数据挖掘相关的课程，并对相关知识进行了项目实操巩固， 在实习期间获得了很多的项目经验，进行了浙江省区采购数据分析\n、教育平台的线上课程智能推荐策略、信用卡高风险客户识别等全真企业案例实训。"]}
{"1472772112841310208": ["本人在该项目中的工作：1.使用tensorflow2.0的keras搭建LeNet模型 2.将已有标签的数据输入模型进行训练、调优和测试。", "为减少水质评分的时间成本和对专家经验的依赖，现搭建一个机器学习模型来实现水质的自动评分。该项目中，本人的工作：1.使用Python对训练进行集图像进行目标区域提取 2.提取目标区域的颜色矩作为样本特征 3.调用sklearn库，实例化决策树模型 4.模型训练和验证。", "本项目目的是搭建一个用于预测未来天气（如PM2.5浓度）的模型。该项目中，本人的工作：1.使用Python对组员爬取的天气数据进行处理：数据清洗、数据规约等 2.将数据划为训练、测试集 3.用tensorflow2.0的API——Keras搭建LSTM模型 4.模型训练、测试与评估。", "学习内容概述：\n1.Python网络爬虫与案例\n2.Python数据分析、可视化与案例\n3.机器学习原理与案例\n4.深度学习原理与tensorflow2.0\n6.机器视觉案例\n7.自然语言处理案例 \n8.MySQL数据库应用 \n9.了解与搭建Hadoop、Hive、Spark大数据集群\n10.案例详见“项目经历”一栏。"]}
{"1472476777166274560": [null]}
{"1487091440004759552": null}
{"1467802081468481536": ["1、围绕GeoGebra的功能，与小组成员探讨、确定项目任务；\n2、查找相应的学习资源，自主学习Geogebra的相关知识； \n3、制作一个面向高中生的教学视频，该视频可以帮助同学们提高空间想象能力，更容易理解关于几何的知  识点，从而提高课程成绩。", "1、资料收集：根据作业要求，自行收集公开数据集，获取项目数据；\t\n2、对比分析：分析不同的算法模型对所用数据的效果（预测的准确率），择优选择两个算法进行报告；", null]}
{"1470307844552261632": ["本项目采用了Excel、PowerBI操作工具和技术，进行四川智慧旅游大数据分析和可视化操作，制作可视化分析仪表盘。 该项目主要内容有： \n1 获取四川国庆节期间旅游的相关数据，熟悉各数据文件中的字段涵义\n2 学习PowerBI软件并使用其为数据绘制恰当的可视化图形 \n3 绘制地形图展示游客主要来源于哪些省份；使用环形图展示不同年龄段、性别、出行方式的游客占比；使用条形图形，展示游客人数前10的旅游线路、热度值等。\n4 使用按钮控件，选择展示不同日期的数据。", "肥料是农业生产中一种重要的生产资料，其生产销售必须遵循《肥料登记管理办法》，依法在农业行政管理部门进行登记。本项目的主要目标是从省份、日期、生产商、肥料构成等维度对肥料登记数据进行对比分析。\n\n内容描述：1）首先对肥料登记数据进行预处理，使用replace函数对肥料名称进行规范化； 2）肥料产品的数据分析，利用cut函数将产品分组并打上分组标签，根据分组情况绘制产品的分布热力图，构建KMeans模型将产品聚为四类，根据聚类标签绘制三维散点图和散点图矩阵； 3）肥料产品的多维度对比分析，绘制折线图分析各组别不同年份肥料登记数量的变化趋势，分析不同省份有效期内有机肥料产品的分布差异，计算产品登记数量大于 10 的企业间的杰卡德相似系数； 4）肥料产品的肥料构成分析，利用正则表达式提取字符串中各养分的百分比、原料的名称及该原料百分比。\n", "主要内容：python数据分析、python数据可视化、机器学习、TensorFlow深度学习、MySQL数据库等。"]}
{"1468079045689344000": ["本项目针对某平台的经营数据，对该平台各行业每月的盈利情况进行分析，对各行业投入分配比重提出建议。分析母婴行业该部门的运营情况、财务状况、物流管理等不同维度的分析，评估该部门的健康状况和发展趋势，对部门经营策略进行改进优化。本次项目采用python数据分析、数据可视化等技术，主要使用pandas、matplotlib、seaborn库可视化分析数据。", "对原始数据进行数据探索并处理数据异常值、缺失值、重复值；提取出年龄特征绘制折线图分析该航空公司的主要客户群体；利用 seaborn可视化库绘出该航空公司各省份工作客户人数热力图并基于RFM客户价值模型进行特征构建；使用for循环找出最优参数构建KMeans聚类模型；使用轮廓系数和簇内误差平方和评估模型并绘制系数图，最后绘制雷达图分析客户价值。", "主要内容：python数据分析、python数据可视化、机器学习、TensorFlow深度学习、MySQL数据库等。"]}
{"1473584370802622464": null}
{"1461534785997504512": ["负责大数据分析项目开发，主要负责通过网络爬虫获取互联网数据，并通过数据预处理方法清洗整理数据"]}
{"1470309548341460992": ["本项目通过对网络法律服务网站进行分析，由此获取当前人们对法律网站的浏览、点击等行为的统计来分析当前人们对法律服务的使用认可情况", null]}
{"1461512488951611392": null}
{"1479478335108153344": ["本系统采用B/S架构运行，并且采用三层软件体系架构，即表示层、应用层和数据层构成。其中表示层是系统的用户接口，即用户UI，在这里体现为Web显示页面，主要用HTML标签语言来展现。应用层是本例的功能层，即应用服务器，位于表示层和数据层之间，负责具体业务逻辑处理，以及与表示层、数据蹭的信息交互，主要用PHP脚本语言来实现。数据层位于系统的最底层，具体为MySQL数据库服务器，主要是通过SQL数据库操作语言，负责对MySQL数据库中你那个的数据进行读写管理，以及更新与检索，并于应用层实现数据交互。", "一对一家教", "一对一家教"]}
{"1473188657572741120": ["?学习并操作Python基础编程\n?培训并参加Python数据分析实战经验，熟悉数据的处理流程，包括数据的清洗、预处理、存储、分析挖掘和可视化\n?了解数据挖掘常见算法：分类/聚类，降维方法，逻辑回归，决策树，支持向量机(SVM)等\n?配合完成小组内模拟系统的后台定制化开发工作，对数据链业务逻辑进行重构优化"]}
{"1469191500528222208": ["1、数据挖掘挑战赛项目开始从 2021 年 4 月——2021 年 5 月。本人担任项目组长，项目是《基于深度学习的岩石样 本的智能识别及石油含量检测》。 2、项目的目标是在运用深度学习的图像学习技术对岩石样本识别与分类，来对地质进行研究，与岩石含油量进行预 测。目前岩石样本识别的方法主要有重磁、测井、地震、遥感、电磁、地球化学、手标本及薄片分析方法等方法，而 采用图像深度学习的方法建立岩石样本自动识别分类模型是一条新的途径。 3、本项目通过对图像进行依标签进行分类建立起图像数据集，然后对图像数据集进行预处理，因为该图像数据集的 样本只有三百多张图片，不足以提供训练与测试所需的样本，所以要对该图像数据集进行图像增广，然后把数据集样 项目经历\n本量提高到 3000 多张图片，这样就能防止因为数据量太少使模型的泛化能力太低，而出现过拟合现象。"]}
{"1473588907194056704": ["使用 python 语言对数据进行预处理，如数据拼接、缺失值的剔除与插补、异常值处理以及数据标准化，然后进行无关变量的剔除，剔除对问题的研究无影响的指标。由于数据是不均衡的，所以对数据尝试了朴素随机过采样、SMOTE 过采样等，然后尝试构造了支持向量机、决策树、逻辑回归、集成学习分类器等模型，最后调用函数进行模型评估，包括查看混淆矩阵、ROC 图、AUC 值、F1 值等，对各个行业选出最优模型去进行模型预测，预测不同行业的些上市公司进行了造假。\n", "使用 python 语言对原始数据进行读取与探索，如空值、重复值、异常值等，然后根据探索出来的问题进行数据预处理，主要是数据清洗和数据规约。完成预处理后对数据进行分析，及结合pandas、matplotlib 等第三方库进行可视化。分析包括：绘制饼图查看家电行业中商品品牌的占比；使用 groupby 函数查看各仓库的库存周转量并用柱状图展示；使用 pandas 透视表制作不同平台的商品采购价表；对比各平台在母婴、酒饮行业的采购量并绘制折线图进行查看等。", null]}
{"1463080366905622528": ["以应用统计学的核心课程概率论，数理统计，应用回归分析等课程为试点，探索以shiny为工具，制作交互可视化内容。将抽象知识直观化，达到激发学生学习兴趣的效果。", "根据平台把握用户信息，掌握用户课程偏好并提供精准的远程课程推荐服务，利用数据分析技术对教育平台的线上信息和用户学习信息进行研究，分析平台用户的活跃情况，计算用户的流失率，为平台管理决策提供建议；分析线上课程的受欢迎程度，构建课程智能推荐模型，为教育平台的线上推荐服务提供策略。", "水产养殖的关键因素之一是水质，养殖水体生态系统的平衡状况可通过水质颜色体现，传统水质监控的局限性在于对鉴别师的个人经验要求高，存在主观性引起的观察性、可重复性不高，不易被推广应用。本项目实现在线水质检测，通过计算机视觉、数字图像处理技术、专家经验（专家数据）和机器学习算法实现水质的自动评价。", "本次项目是调用Opencv库进行人脸图像的获取、导入和人脸的检验；通过随机翻转、随机旋转的方法进行数据增强；构建网络模型，模型编译优化器使用adam优化器，损失值计算方式是稀疏分类交叉熵等计算器视觉技术实现动态人脸识别。\n", "把留言数据使用正则表达式进行数据的清洗，使用jieba库对留言详情进行分词，使用pickle实现对分词结果的序列化。建立机器学习中的密度聚类（DBSCAN）模型与深度学习中的卷积神经网络（CNN）模型两个方案来解决留言分类。", "培训内容包括：数据分析与应用、数据可视化、网络爬虫、机器学习、深度学习原理及编程实现、计算机视觉及项目实战、自然语言处理及项目实战、MySQL 数据库项目实战、Linux 基础、hadoop 架构、hive、Spark架构等\n", "1.协助疾控中心工作人员开展对中小学的健康情况调查\n2.到每个中小学学校对学生的视力、身高、体重等身体健康情况指标进行调查\n3.数据整理与录入系统\n", "1.参与玉林市食品安全调查\n2.在街道上寻找路人填写问卷，并统计数据", "1.对参加“乡村新入职教室培训——国培计划”的学员展开满意度调查\n2.收集问卷数据，分析数据，撰写分析报告\n", "1.负责调查群众的安全感满意度工作 \n2.通过电话调查的方式，访问群众\n3.数据整理与录入，保证数据有效性，正确性。\n", "1.负责玉林市玉州区第七次人口普查工作，逐一落实到每户每人 \n2.负责信息录入，信息录入，保证数据的真实性、准确性、完整性和及时性。\n", "成绩单", "个人简历附件", "基于Shiny的机器学习交互式可视化平台教学研究与应用，在知网、万方、维普、龙源、总署可检索"]}
{"1470203287771938816": ["在泰迪我学习到了跟大量跟大数据相关的新知识"]}
{"1473849820266496000": ["该项目主要是根据网站会员流失预测业务需求，建立专用的项目，对数据进行清洗、转换、以及异常数据处理，进行数据规律探索；与业务人员探讨用户行为特征，结合数据规律确定量化建模特征，协助进行模型选定、建模调优、模型评判等工作，形成一套完整的用户流失预警维护方案", "参加广州泰迪智能科技有限公司组织举办的为期4个月的“大数据分析及工程实践”培训。通过此次培训，我对数据分析技术有了更深刻的理解和认识，对数据分析工作内容有了更深的体会。培训内容如下：\n（1）大数据分析理论：数据探索、数据预处理、爬虫工程、机器学习（KNN近邻算法、决策树算法、K-mean聚类分析等算法）、深度学习、数据库等基本操作和技术。\n（2）主要语言学习：Python，Mysql。\n（3）全真企业案例实训：教育平台的线上课程智能推荐策略，餐饮企业综合数据分析，网站会员流失预测"]}
{"1469220920555077632": null}
{"1462716135081377792": ["本项目根据教育平台把握用户信息，掌握用户课程偏好并提供精准的远程课程推荐服务。", "使用020场景相关的丰富数据，通过分析建模，精准预测用户是否会在规定时间内使用相应优惠券", "系统学习数据分析课程，如Python、SQL、Linux等。", "1、负责门市的日常经营工作；\n2、按照产品标准流程制作奶茶等饮品；\n3、POS机操作及收银；\n4、处理好线上订单问题。"]}
{"1470370854457180160": ["描述：对数据进行探索分析，预处理；初步归纳健身用户的健身特征，提炼出健身属性特征，构建样本数据集，然后用spark读取的rdd数据集转换为dataframe，运用sparksql对数据集进行对比分析，采用sparkML来预测健康问题，抽取特征与转换、构建决策模型、构建算法评估器", "描述：对数据进行探索分析，预处理；对数据进行少量分批实时采集，从处理后的数据中提炼出图书热度的属性特征，结合历史数据构建成样本数据集,然后运用spark对样本数据集进行切分，分组，合并，统计处理，得到目标模型，实现图书热度实时统计。", "在该公司对大数据开发这一方向深入学习，学习开发语言的编写、应用，学习了解各种组件的原理、应用，自主完成一些课题，尝试挑战一些案例、项目"]}
{"1468143289352978432": ["房价是国人最关注的话题之一，由于国内的房价起伏过大，存在诸多不确定因素，所有我们选择了美 国房价进行统计分析。美国房地产已有 200 多年的历史，房产市场十分成熟，其数据对我们有重要的借鉴意义。 \n开发工具：Hadoop、Spark、Hive", "1.掌握基本的 Java 基础编程语言 \n2. 熟悉 Linux 操作系统、掌握 Linux 基本命令及 X-shell 基本操作 \n3. 掌握 Hadoop、Hive、Spark 的基本语法及操作 \n4. 对综合案例进行研究，对案例数据进行分析和探索", "1．教授小学、初高中数学\n2．合理安排学生课时，保证学生按时上课\n3.辅导学生作业", "1. 负责检票、领位、巡场及清场等工作，有效的控制及疏导观众候影及观影的秩序；\n2. 负责影院大厅内、影厅内灯光照明、空调温度的调节，确保适宜及正常；\n3. 负责影城内的整体巡视工作，禁止观众吸烟、摄影录相、携外带食品及窜厅等现象；\n4. 与放映部门的及时沟通，确保为观众提供良好的观影环境，保证影片正常放映；\n5. 如有需要时，需为观众介绍影城的促销活动并进行销售推荐，或为观众解答影片票价、影城优惠等；\n6. 完成领导交办的其它工作。"]}
{"1473588605648764928": [null]}
{"1472845935146041344": [null]}
{"1472869555029278720": ["了解并初步掌握Hadoop + Spark等大数据开发核心工具，并应用于实际工作；熟知大数据开发或数据分析挖掘项目的基本流程，建立良好的数据思维；了解常见大数据开发和数据分析算法原理及编程实现。"]}
{"1472830533502369792": null}
{"1472843479926308864": null}
{"1473128370643533824": null}
{"1466238166611656704": ["采用图像深度学习的方法建立岩石样本自动识别分类模型项目描述： 项目的目标是在运用深度 学习的图像，学习技术对岩石样本识别与分类，来对地质进行研究，与岩石含油量进行预测", "能初步了解大数据框架，并在不断学习进步"]}
{"1473478366115004416": ["基于Fisher-score的特征选择+卡方检验进行特征提取，通过随机森林模型预测第6年财务数据造假的上市公司。\n主要的任务是数据预处理、特征提取及收集特征意义、数据分析、撰写分析论文报告", "在此次培训经历中,学习的主要课程有 Python编程基础、 Python数据分析与应用、 Python数据可视化、 Python网络爬虫、 Python机器学习、综合项目实战、深度学习原理及编程实现、计算机视觉及项目实战、自然语言处理及项目实战、 MYSQL数据库、MYSQL数据库项目实战、 Linux基础、 Hadoop、hive、 spark。重点学习Python基础与数据分析、应用"]}
{"1469265154083520512": null}
{"1471800130456911872": ["根据数据使用python对数据进行 熟悉业务环境、数据预处理、数据分析以及数据的可视化；\n对平台上不同省份、不同行业、不同品牌进行多维度对比分析并得出结论提出建议", "结合python对景点和酒店的网络评论内容进行文本有效性分析、制定评分系统和文本挖掘，并根据结果提出建议", "基于GRU神经网络算法模型处理股票高频数据，并运用长期高频分钟股票行情数据进行数据预测并对时间顺序进行分段取值实现数据压缩后进行滚动预测，最终构建了基于GRU神经网络算法模型来实现对股票的预测 。", "在此次培训中，我们学习了数据分析、数据库、大数据相关知识，以及宝贵的实战经验，在培训过程中，会讲解数据分析实例并且会给予我们一定的实战练习时间，保证知识与实践相结合，定期会有个人作业和小组作业来巩固知识。", "在规定的两周时间内，入户调查和留守儿童的信息采集，帮助留守家庭了解相关扶贫政策，并与村干部协助政策的申请以此改善留守儿童家庭情况；\n在一周的时间内，对收集到的信息进行数据的整理以及电子录入", "根据绘制的关系图进行不同部门的数据分析并通过 powerBI 绘制相应的可视化报表以及对成本、毛利率和库存周转周期性变化等进行分析报告；\n负责协助数据分析师与其他部门的同事进行数据收集与整理，对不同部门的数据进行数据关系的梳理并绘制相应的关系图；\n后期使用 python和excel 根据生产线的数据对不同客户的订单情况进行预测分析\n"]}
{"1470960841070346240": ["根据景区及酒店的网评文本及得分，使用python进行文本分析。对景区及酒店的网评文本数据预处理，分词并去停用词，词频统计绘制印象词云表，做文本印象分析。建立LDA模型并训练，分析景区及酒店的特色，对景区及酒店网络评论的进行有效性分析，并撰写分析报告。\n", "学习Python数据分析、Python数据可视化、网络爬虫、机器学习、TensorFlow基础、图像处理、自然语言处理、mysql数据库、hadoop、hive、spark基础知识"]}
{"1469877468583297024": ["对数据进行探索分析，数据预处理；对处理后的数据进行数据标准化，提取出各行业与财务数据造假相关的数据指标；针对制造业各上市公司的财务数据建立SVM、决策树、逻辑回归等模型，对各模型预测效果进行评估，对比取最优模型对制造业第6年数据造假的上市公司进行预测。", "对数据进行探索分析，数据预处理；对处理后的数据特征进行相关性分析；对变量进行处理，构建线性回归模型；使用模型对共享单车使用量进行预测。", "学习数据分析相关课程，如Python编程基础、深度学习、SQL数据库等课程。"]}
{"1463077032337473536": ["根据所给的380平台数据，进行数据分析，完成年度总结报告工作。通过对负责的平台中母婴部门的运营情况、财务状况、物流管理等不同维度的分析，评估该部门健康状况和发展趋势，指导平台发现问题并进行优化。", "根据所给的各地区旅游游客评论文本数据，对游客目的地选择的影响因\n素进行量化分析，推断挖掘影响游客满意度的核心因素，并针对此为旅游业提出意见", "【项目背景】：\n在金融市场上，信息的连续影响着证卷市场的价格运动，数据的采样频率越高，信息的丢失程度就越低、越能更加真实的反应金融市场上的问题，也有助于理解微观金融市场的结构体系。\n\n【项目目标】：\n运用不同的算法模型及方法处理具有非线性、非平稳、高噪声的长期高频股票交易数据，分析其预测效果的差异性。\n\n【项目职责】：\n1、对15支医药股票进行预处理以及拆分处理；\n2、分段压缩数据；\n3、根据分段压缩后的数据，调整数据集进行滚动预测。\n\n"]}
{"1468110505502703616": ["项目简介：采用产品的销售额和利润数据，对其盈利能力进行分析和预测，给决策人员提供分析报告，以便为非洲各国提供更 好的产品销售策略和服务。 项目职责：本人基于Python对数据进行预处理；计算各国、各服务分类销售额和利润的同比增长率；统计各地区、国家有关服 务分类销售额和利润数据，各个销售经理的成交合同数和成交率；根据地区、国家等维度，绘制各服务分类的销售额和利润的 年增 长率及各季度同比增长率的图表等。 项目结果：获得泰迪杯数据分析技能赛A题二等奖。", "对肥料登记数据进行预处理；根据养分的百分比对肥料产品进行细分；从省份、日 期、生产商、肥料构成等维度对肥料登记数据进行对比分析；对非结构化数据进行结构化处 理。项目职责：本人基于Python对数据进行剔除无效数据、规范类别名称等预处理过程，绘制图表 分析数据，对非结构化数据进行结构化处理等。", "学习使用Python进行数据获取、数据预处理、模型构建、数据分析等。 主要课程：Python数据分析与应用、Python数据可视化、MySQL数据库、Python网络爬 虫、机器学习原理及编程实现、计算机视觉、深度学习及编程实现等。", null]}
{"1468114577727291392": ["采用 Python 语言进行数据预处理、构建矩阵、算\n法构建。通过分析用户的观影记录和评分数据，\n构建评分矩阵，构建模型实现为用户提供个性化\n的电影推荐。", "基于包含良性和恶性乳腺肿瘤的显微活检图像数据集，通过一系列图像处理，应用卷积神经网络对乳腺癌组织病理图像进行分类。", "1.  掌握 Matplotlib、seaborn、Pyecharts可视化绘图并分析；\n2.  掌握并应用 requests 库、Xpath 库、Selenium 库进行网络爬虫；\n3.  掌握决策树、KNN、朴素贝叶斯等机器学习算法；\n4.  基于 tensorflow 的 CNN、RNN 深度学习算法；\n5.  掌握图像几何变换、转换图像颜色空间等图像处理操作。"]}
{"1469222725271814144": null}
{"1468108701696131072": ["学习了使用python进行数据分析的方法，SQL的增删改查等数据分析基本技能"]}
{"1471778230154428416": null}
{"1469590908960899072": ["1、\t项目简介：通过对数据预处理、存储、查询和可视化分析等数据处理操作，对护肤品销售数据进行分析，筛选出口碑排名靠前的产品、判断各类护肤产品是否与商家描述一致以及性价比高低等，为顾客购买适合自身的护肤产品时提供参考。\n2、\t项目职责：\n(1)\t对获取到的数据集进行预处理\n(2)\t数据导入Hive后，对数据进行分析\n(3)\t通过Pythond对数据进行可视化分析\n", "1、\t项目简介：针对传统的骨质疏松诊断方法中存在的流程过于繁琐、提取特征的人工成本太高等问题，提出了基于磁共振影像的骨质疏松智能诊断技术，由脊椎骨分割算法和骨密度分类算法组成，加快骨质疏松的诊断速度，减少骨质疏松症的误诊漏诊率。\n\n2、\t项目职责：\n(1)\t收集数据，标注处理收集腰椎部分区域的磁共振医学影像，建立数据集。\n(2)\t基于Mask R-CNN的图像分割模型完成模型训练，保存最优模型。\n(3)\t对分割后的图像进行数据增强操作。\n(4)\t搭建神经网络ResNet50分类模型自动从骨质疏松图像挖掘图像的病理特征，获取能够区分骨密度正常和骨质疏松的能力。\n", "学习掌握python编程技术，提高python编程能力，学习掌握MySQL,提高自身专业知识和应用能力", "在该公司任职线上品牌文化传播实习生，通过大数据在各大社交平台寻找合适的博主推广品牌产品，与各平台博主商谈合作事宜，跟进合作事项，收集整理产品推广数据，通过实习了解大数据下的文化宣传。"]}
{"1471283827795165184": ["       在广州泰迪智能科技有限公司进行四个月的数据分析挖掘实习，学习了大量数据挖掘相关的课程，并对相关知识进行了项目实操巩固， 在实习期间获得了很多的项目经验，进行了浙江省区采购数据分析\n、教育平台的线上课程智能推荐策略、信用卡高风险客户识别等全真企业案例实训。"]}
{"1470307492838899712": ["参加广州泰迪智能科技有限公司组织举办的为期4个月的“Python数据分析”的培训及实训。Python数据探索、预处理、统计分析、\n可视化、数据挖掘算法、深度学习等。\n企业实训案例：京东手机评论数据情况分析、信用卡高风险客户识别、教育平台的线上课程智能推荐策略等。"]}
{"1471662236597616640": null}
{"1470772609334509568": null}
{"1470680541211787264": ["本次项目针对智能政务系统对群众留言分类、热点问题挖掘以及答复意见评价三方面 问题，我们团队分别通过文本特征词分析、文本相似度分析、时间排序、热度计算及排序、文 本主题模型、文本结构分析，对应问题要求达成目标。", "为避免投资‘踩雷’，本次案例采用并基于 XGBoost 算法、ADASYN 自适 应综合过采样算 法、逻辑回归、分类决策树及随机森林算法，并根据 2018 年我 国《三次产业划分规定》，对 各行业进行产业划分，对各个公司进行了判断是否 为造假数据的预测。利用机器学习算法，充 分使用原始数据，融合多种算法，且建立的模型 预测结果较为稳定，具有参考价值和实现意义。", "在培训中我学习到了数据分析挖掘建模的理论基础，并结合企业案例实训对理论知识进行了实现，并自行或以小组形式完成了‘基于分类模型，对银行客户数据进行分析，预测其是否购买银行定期存款产品’和‘基于深度学习的肝脏肿瘤分割’两个案例。"]}
{"1467793287824932864": null}
{"1469193231341322240": ["培训内容：Java程序设计，Linux操作系统，SQL基础，Hadoop大数据基础，Hive数据仓库，ZooKeeper分布式服务框架，HBase非关系型数据库，Scala基础，Spark大数据技术与应用，Flume数据采集，Kafka大数据数据流处理，Flink大数据实时处理，分布式文件搜索ElasticSearch。"]}
{"1470682511054077952": ["对Hadoop集群及其相关插件的学习"]}
{"1470745702312312832": ["  通过酿酒葡萄的理性指标和评酒员的评分，来对酿酒葡萄进行分类。综合考虑酿酒葡萄和葡萄的理性指标与葡萄酒的质量的关系。项目使用工具描述：通过 Matlab 进行数据正态分布拟合，用 SPSS 软件中的主成分分析算法来对指标进行降维，\n使用 Python 中的 k-mean 算法分别对红葡萄酒和白葡萄酒进行分类。项目职责：在团队中主要负责收集相关资料、提供解决思路、负责数据的预处理、酿酒葡萄分级模型的建立、撰\n写部分分析报告。", "项目架构：通过 Linux 脚本命令实时产生新数据文件；使用 Logstash 采集产生的数据文件传输至 Kafka；Spark \nStreaming 获取 Kafka 端数据，保存至 Elasticsearch；通过 Kibana 对数据进行实时可视化。\n（框架流程图：https://www.processon.com/view/link/61b9db7ef346fb024cbbd11d）", "hadoop、Spark、Kafaka、Flume、Elasticsearch等大数据平台的基础教学，和相关案例的实现", "* 负责电邀，向客户介绍该教育系统的功能以及优点，邀请客户带孩子 \n   参加课程体验\n* 带学生上课程体验、讲解该教育系统的使用方法\n* 带学生上晚自习，解答学生问题，管理课堂纪律"]}
{"1470677375170772992": ["培训内容为学习大数据开发的组件，包括Linux,Hadoop,MySQL,hive,hbase,spark等"]}
{"1470640986240712704": ["项目在Python语言的基础上进行，完成以下目标：\n1.构建算法设计出岩石岩性智能识别模型，利用深度学习算法，构建RegNet模型，训练后的模型使用混淆矩阵对模型进行评价，完成岩石岩性的智能分类。\n2.对数据进行集成处理，通过opencv、高斯滤波以及hsv等算法，利用石油在紫外线照射下具有发光的特征，得出岩石含油面积百分含量。", "此次培训的课程内容主要为语言基础知识和大数据开发组件知识的学习实践，如：数据采集Flume与Kafka、数据仓库Hive、Hadoop、spark、Flink等等。在经过此次学习后，我自身可以根据课程内容去独立的完成一些案例实践。", "1.项目部每日收集资料的整理与电子归档\n2.短期权籍测绘与权属调查\n3.协助项目部成员实现不动产数据衔接与数据库建设，与所属区域居民交涉沟通"]}
{"1470307323162525696": null}
{"1470309366568714240": ["建立岩石样本岩性智能识别模型与调优，实现对岩石样本的识别并计算其含油量；\n负责与团队其它成员沟通并进行相关论文的撰写与修改。\n", "课程：Java基础、Hadoop、Hive、Scala、Spark、Kafka、ES等\n\n案例：广电大数据画像、图书热度实时统计"]}
{"1470957711746269184": ["随着互联网技术发展，传统的技术在造价行业力不从心，其中一个方面就是建筑材料的非标准化， 各个地区各个材料的标准不一致，写法千奇百怪，为了做出能作为行业级别的材料命名标准规范，收集整个 平台以及爬取到的其他平台所有的材料数据，运用机器学习的方法，给不同分类不同规格不同写法的材料一 套标准的命名规范和自动识别。", "培训内容如下：\n（1）Python编程基础 、Python数据分析 、Python数据可视化 、Python网络爬虫 、Python机器学习实战 、TensorFlow实战 、MySQL数据库 等\n（2）语言学习：python、MySQL\n（3）全真企业案例：01-浙江省区采购数据分析、02-餐饮企业综合案例分析、03-人脸识别、04-新闻文本分类、05-（MySQL）O2O优惠券处理", "负责初中数学辅导教学", "负责家长接待、招生、课表安排等相关事宜"]}
{"1470284037246550016": null}
{"1467790182290948096": ["对SQuAD阅读数据集进行英文文本处理和文本向量化，计算文本相似度，对输入的问题检索出相似度最高的问题并返回答案。", "对脑部正电子发射计算机断层显像进行研究，构建模型对阿尔茨海默综合症进行分析和预测。", null, "主要辅导学生基础知识和课后作业辅导", "主要管理楼面大小事务，组织分配楼面服务员的工作和召开晨会；积极与顾客沟通，满足顾客的需求。"]}
{"1470316546227306496": ["2019年上映的《复仇者联盟4》创下了全球史上票房第一名的好成绩，为了进一步深入了解其创下第一名票房原因，获取了豆瓣网站用户对《复仇者联盟4》的观影短评数据，分别对用户城市分布、用户会龄分布、评价及观影时间、短评关键信息进行分析，由分析结果得出结论。", "水产养殖的关键因素之一是水质，而水质可以通过水的颜色体现，将已拍摄好的水样图像进行处理，得到只有水色的图像，对其进行水质分类。依据水色图像的颜色矩进行特征构建，利用机器学习的分类算法进行水色图像归类，识别其水质，分析水质情况是否适合水产养殖。", "爬虫过程中往往会遇到IP被封的问题，而使用代理 IP 就可以很好的伪装自己，保护主机IP，快代理是一个分享免费IP的网站，对该网站进行爬虫，保存可以使用的代理IP。", "视频平台网站往往希望能够提高用户的访问率，而有相同偏好的用户，观看同一部电影的概率较高。因此，在某个用户观影结束后，可以根据用户与其他用户之间的相似特征进行合理分析，通过协同过滤算法进行电影筛选，实现电影的智能推荐，提高用户的电影观看率。", "人脸识别是利用摄像头采集人脸图像，进而对检测到的人脸进行脸部识别的技术。人脸识别技术应用广泛，在公司、学校，甚至是手机上都常常能够见到人脸识别系统，人脸识别技术不仅能够快速识别我们的身份，还能防止被他人冒用身份，被广泛运用与生活中。", "主要对Python数据分析进行培训，培训内容有数据清洗、数据可视化、数据建模、网络爬虫、机器学习、深度学习、计算机视觉、自然语言处理、MySQL、Linux等。", "这是我的个人简历"]}
{"1467790027760205824": ["运用 hadoop 分布式存储计算平台等大数据方法，对汽车销售的各项数据进行分析， 通过评估得到最优的营销方案。", "运用 Apriori 关联规则分析出大部分人的购物习惯，由此推测商城商品的相关推荐和摆放位置的最佳选择。", null, "负责兆阳 o 立方物业营运服务工作，与客户进行合同交接并记录，及时跟进、解决问题； 做好段诉处理和客户需求的记录，对客户需求进 行分析与反馈。"]}
{"1466004681011625984": ["利用python数据分析、可视化大屏等工具对2020年中国新冠疫情分布数据进行数据挖掘，利用多种分析手段对疫情数据进行解读分析，以消除公众的恐慌情绪，提高人们的自我防护意识\n需求实现：\n1. 对疫情数据进行简单的统计。\n2. 设计可视化数字大屏展示新冠疫情的时空变化情况。\n3. 对国内疫情变化情况进行分析。", "利用python自然语言处理、数据分析、可视化等工具挖掘广州景区及酒店评论数据，寻找提升景区及酒店等旅游目的地美誉度\n的因素，探索如何稳定客源、取得竞争优势、吸引游客到访消费等重要事项的方法。\n实现4个需求：\n1.提取景区及酒店TOP10热词\n2. 利用景区及酒店平台评论构建评分模型，与景区及酒店实际评分进行均方误差计算模型准确率\n3. 计算景区及酒店评论相似度，探索评论是否为意义的水军评论\n4. 根据前3个需求的结果探索景区及酒店的特色，探索其如何更好地提高营业额", "1）创建数据生成模块\n2）创建数据库\n3）实现mysql与kafka交互\n4）读取 Kafka 数据之后，并对 MySQL 中存储的黑名单数据做校验；\n2）校验通过则对给用户点击广告次数累加一并存入 MySQL；\n3）在存入 MySQL 之后对数据做校验，如果单日超过 100 次则将该用户加入黑名单。\n", "sparkstreaming实现实时统计每天各地区各城市各广告的点击总流量，并将其存入 MySQL\n1）创建数据库，导入数据\n2）单个批次内对数据进行按照天维度的聚合统计\n3）结合 MySQL 数据跟当前批次数据更新原有的数据", "1）创建数据库\n2）导入数据\n3）利用sparksql窗口函数开窗确定时间范围；\n4）在窗口内将数据转换数据结构为((adid,hm),count);\n5）按照广告 id 进行分组处理，组内按照时分排序。", "进展中", "进展中", "系统性学习大数据开发组件，hadoop生态体系，如hadoop、hive、zookeeper、hbase、spark、flink、flume、kafka、es等"]}
{"1469170123129618432": ["本项目采用对数据量需求较大的深度学习方法进行研究实验，项目的医疗影像分割及智能诊断技术，能减少骨质疏松症的误诊漏诊率，提高医生工作效率", null]}
{"1469243148147490816": ["在泰迪智能科技公司进行为期四个月的大数据分析培训及实训，获益良多。", null]}
{"1470189224509702144": [null, "学习了Hadoop、hive、spark、Kafka、flume、es等大数据开发工具"]}
{"1470021059326640128": ["基于Python的供应链经营数据分析项目，提出研发过程改进思路，协同其他成员制定研发动作检查项、项目复盘机制的建立。", "通过Python网络爬取人民网科技栏目中2020年7月1日到11月30日的新闻。内容包括: 新闻标题，发布时间，新闻内容。最后以表格的形式存储。通过分析目标网页和基于Python 的网络爬虫实现： 1、使用http request 请求模块来获取网页整体资源。 2、使用Beautiful Soup4模块来获取网页细节资源。 3、使用工具：Jupyterbook。", "运用Python对微博评论文本的数据进行采集、数据清洗和预处理、建立基于BERT的中文短文本情感分类的模型。", "培训内容如下： 1、学习Java、Linux、Scala的编程语言运用。2、掌握Mysql、Hive、Hbase对数据进行查询和存储等操作。 3、搭建和熟练hadoop、zookeeper、Spark、Flume、KafKa的应用等。 4、案例实训： 基于关联规则的菜品智能推荐 、航空公司客户价值分析、 电商评论数据情况分析 、美国房价数据统计分析 、分析法律服务网站数据 、网络入侵自动识别 、广告流量作弊识别 、图书热度实时统计分析、商品实时推荐", null]}
{"1463446413584236544": ["对数据进行数据预处理，构建特征，使用k-Means聚类算法，绘制雷达图，对客户群体进行分群，探索最终得到不同客户群体的客户特征及对应的营销策略。", "使用Jupyter notebook进行数据的爬取，发送http请求并解析网页（去除前后无关字符、将字符串转化为字典、提取信息），对数据进行预处理，分别绘制好评、中评、差评的词云图，最后总结。", "通过对文本内容对文本进行分类，一共有四大类文本分类，分别是女性、体育、文学和校园，第一步先准备语料，第二步对特殊字符进行预处理，第三步对文本内容进行分词和去停用词，第四步文本转化为向量，第五步进行模型的实现，分别使用机器学习的朴素贝叶斯方法和深度学习的全连接网络模型进行模型的搭建及训练，最终进行模型的评估。", "学习Python语言的数据结构和对数据的基本管理，能对数据进行清洗、可视化、建模、预测、评估、优化。其中包含机器学习的线性回归分析、关联规则、KNN近邻算法、聚类分析等常用的数据挖掘算法，还有深度学习的BP、CNN、RNN神经网络的实现，还有接下来即将学习的MYSQL、Linux、Hive、Spark。"]}
{"1470309657343033344": null}
{"1469199771200782336": ["主要学习Hadoop、hive、Kafka、spark等大数据开发工具。"]}
{"1470244930722070528": ["对一份岩石样本图像数据集，通过图像处理技术和深度学习算法，设计出有效的模型识别出岩石样本的岩性类别及含油气情况，实现岩石样本智能识别分类。\n\n\n", "实现实时的动态黑名单机制：将每天对某个广告点击超过 100 次的用户拉黑，幵且将黑名单保存到MySQL 中。\n", "根据用户在浏览公司站点时的行为习惯和消费习惯，收集用户在站点的实时访问数据，并根据用户的购买偏好进行实时商品推荐。\n", "培训内容：学习Java 基础，Linux 操作系统，SQL 基础，Hadoop，Hive，Zookeeper，Hbase，Scala 基础，Spark，\nFlume，Kafka，Flink，ES等大数据开发技术。\n"]}
{"1470235062837575680": ["1.学习Java程序设计，Linux操作系统，SQL基础，掌握分布式系统Hadoop，\n2.Hive数据仓库，HBase非关系型数据库，ZooKeeper分布式服务框架\n3.Scala基础，运用Spark大数据技术与应用，Flume数据采集，Kafka大数据数据流处理，Flink大数据实时处理"]}
{"1469952429427654656": ["该项目主要使用Spark+Hive实现。首先，编写Spark程序从Hive读取数据文件，并对其做数据预处理，去除数据中的缺失值，删除不相关的字段等；然后对预处理后的数据进行分析，接着，将其中连续型数据进行标准化，并和离散型数据整合后划分出训练数据集和预测数据集；最后，构建决策树模型，训练该模型，并使用测试集计算模型准确度。", "该项目主要使用Flume+Kafka+Spark Streaming实现。首先编写sh脚本模拟数据流的实时生成，并开启定时执行随机抽取的脚本任务；接着组合Flume&Kafka（Kafka Channel）来采集并存储数据；然后再组合Flume&Spark Streaming（Kafka Source、Spark Sink）让Spark Streaming通过Poll的方式从Flume拉取数据并做进一步分析，最后计算图书热度，并将结果保存写入Hive表中。", "了解Hadoop（架构、特点）相关概念；完成Hadoop集群的搭建；掌握集群启动与监控界面使用；理解HDFS、MapReduce、YARN三大框架的原理与架构；掌握HDFS基本操作、MapReduce入门编程；掌握HDFS Java API应用。", "了解Hive相关概念；掌握Hive的安装配置；掌握Hive查询。", "掌握HBase安装配置；了解HBase架构原理；掌握HBase表模式设计；掌握HBase Shell基本操作；完成HBase开发环境配置；掌握HBase Java API应用；掌握HBase与MapReduce进行交互。", "掌握Scala安装配置；掌握Scala基础语法；掌握Scala函数应用；掌握Scala面向对象编程；掌握Scala文件读写。", "掌握Spark安装配置；了解Spark原理与架构；了解Spark RDD概念；掌握Spark编程基础（常用算子）；掌握Spark开发环境配置；掌握本地、集群模式运行Spark程序；掌握Spark SQL应用、Spark MLlib应用、Spark Streaming应用。", "掌握Flume安装配置；了解Flume架构特点；掌握Flume采集任务运行；掌握Flume Agent组件类型；掌握拦截器、Channel选择器和Sink处理器。", "掌握Kafka安装配置；了解Kafka核心概念；掌握Kafka单代理及常用操作；掌握Kafka多代理及常用操作；掌握Kafka开发环境配置；掌握Kafka Producer、Consumer API。", "掌握Flink安装配置；了解Flink相关概念与数据流编程模型；掌握Flink开发环境搭建；掌握DataStream API编程；掌握Flink与Kafka整合实例。", "掌握ElasticSearch安装配置；了解ElasticSearch相关概念；掌握使用ElasticSearch Head浏览添加数据；掌握ElasticSearch基本操作；掌握ElasticSearch+HBase大型搜索系统架构。"]}
{"1469967882053091328": ["在几个月培训期间学习了Java，Hadoop，Spark，Kafka，Flink等大数据开发工具，并且实践了几个项目案例。"]}
{"1469245596702474240": ["1、项目描述：对数据进行探索分析处理，并提取出各行业与财务数据造假相关的数据指标，并通过训练模型预测\n出造假公司。\n2、负责对数据的预处理，如数据拼接，缺失值处理，数据标准化，异常值处理等数据预处理方法\n3、撰写论文", "1、负责招生处想要报读金领技工学校的同学对此学校的具体情况的解答\n2、实时了解学校各方面的变化，了解报读同学的具体需求，为报读同学解决其问题\n3、 在此期间，提前半个月完成招生处规定的报读名额业绩，且报读名额比以往提高了 10%"]}
{"1469932581750439936": ["在为期4个月的培训中，我学到了基于hadoop框架....", null]}
{"1469233133072285696": ["1、负责学生教学工作、通过备课、授课、作业辅导，跟进教学各环节工作，提高学生的数学成绩\n2、负责提升学生学习兴趣，通过与学生及家长沟通交流，分析学生学习情况，提高学生学习自主性"]}
{"1469885228783894528": ["l? 项目介绍：该项目是以录井现场岩屑和岩心在白光条件下和荧光条件下拍摄的样本为研究对象，利用深度学习算法实现岩石样本岩性的智能识别与分类和岩石含有面积百分含量的计算。\nl? 内容：\n- 和队友一起对岩石样本进行数据预处理，包括数据扩增、数据增广以及数据标准化，之后将处理好的图片放入神经网络中进行训练，利用训练好的模型对岩石样本岩性进行智能识别测试；\n- 对图像进行图像分割操作，去除岩石图片的多余背景，之后采用颜色通道（HSV颜色提取）提取得到岩石的含油面积；"]}
{"1469191201306574848": ["对数据进行探索分析，预处理；确定出各行业与财务数据造假相关的数据指标；划分测试集、训练集，构建模型，训练模型，调整模型参数，选出最优模型来预测出第6年财务数据造假的上市公司。", "比较系统的学习了Python，MySQL，Linux"]}
{"1469936306212700160": ["关于本人的大数据开发工程师简历"]}
{"1469243330142535680": ["在每个页面进行埋点，将相关数据发送至日志服务器，日志服务器结合logback将数据通过至Flume客户端，Flume客户端发送至中心日志服务器，中心日志服务器将数据落地至HDFS，以供离线分析，离线分析通过MR将数据清洗处理，将数据存入Hive，使用Hive进行数据分析，完成的结果通过sqoop工具导出到MySQL数据库，通过Superset对数据进行可视化展示，整个过程的流程调度使用Hadoop 生态圈中的 Azkaban 工具。", "编写Linux定时任务，对数据进行定时抽取，根据现有字段完成日志信息模拟产生，设计Flume、Kafka采集系统对产生的日志进行实时抽取，实时分析通过Spark Streaming消费Flume消息来对数据进行清洗和处理，将结果合并为DataFrame并存入Hive。", "参加广州泰迪智能科技有限公司组织的为期4个月的“大数据开发”培训和实训，通过此次实训对大数据开发有了更深刻的理解和认识，培训内容如下：\n大数据核心基础：Java、Scala、Linux、MySQL\n大数据核心框架：Hadoop、Hive、HBase、Spark、ZooKeeper、Flume、Kafka"]}
{"1469873694439505920": ["模拟网上书店，主要包括图书的销售系统、订单系统和用户系统，使用了 Java编程语言、MySQL数据库等工具，实现用户的注册、登录，查看、购买书籍等功能", "学习 Java语言、MySQL数据库\n学习 Hadoop、Hive、Spark、zookeeper等大数据开发框架"]}
{"1469241606338117632": ["主修课程：python基础编程、python数据分析与应用、python数据可视化、python数据分析与应用、python数据可视化、网络爬虫、MYSQL数据库、Hadoop等"]}
{"1469172841671950336": ["（1）Python编程基础、Python数据分析与应用、Python数据可视化、Python网络爬虫、Python机器学习\n（2）深度学习原理及编程实现\n（3）计算机视觉及项目实战\n（4）自然语言处理及项目实战\n（5）MySQL数据库、MySQL数据库项目实战\n（6）Linux基础、Hadoop、hive、spark\n", "（1）利用Excel对人员的档案进行录入整理；（2）对人员商业保险的报销资料进行核查和录入；（3）对人员的\n社保费用进行核查和计算\n"]}
{"1468779175124008960": ["学习java，hadoop，hive，spark，scala，es，相关课程"]}
{"1468155960865456128": ["掌握服务餐饮业务的基本技能，熟悉杏林春日常业务的操作流程以及工作制度，掌握门店核算方法。在我实习的一个月里，客户转换率有一定程度的提升。", "python编程基础、分析与应用、数据可视化、网络爬虫、机器学习，深度学习，计算机视觉，自然语言处理，Mysql数据库，Linux基础", "掌握服务餐饮业务的基本技能，熟悉杏林春日常业务的操作流程以及工作制度，掌握门店核算方法。在我实习的一个月里，客户转换率有一定程度的提升。"]}
{"1468125952079953920": ["在泰迪公司中，接受大数据相关知识的培训，如java基础、Hadoop、HBase、Flink、Spark、ES、hive以及通过利用所学的大数据开发工具对案例的数据进行处理计算和分析。"]}
{"7538494951683452436": null}
{"1469242387086835712": ["1.学习了python,利用python语言进行数据预处理，模型构建，模型预测，模型评估。\n2.自然语言处理\n3.SQL的基本操作，增删改查\n4.虚拟机", "李沛玲，2022届应届毕业生，韩山师范学院，本科，统计学。懂sql基础，以及python,希望成为数据分析师"]}
{"1462717242717372416": ["项目简介：根据教育平台把握用户信息，掌握用户课程偏好幵提供精准的远程课程推荐服务。\n项目职责：\n1. 数据读取；\n2. 数据预处理；\n3. 线上课程智能推荐分析。", "对数据分析所要用到的Python编程基础，pandas、numpy、matplotlib等库，网络爬虫，机器学习，深度学习tensorflow，机器视觉，自然语言处理等进行学习，以及MySql数据库，Linux基础，spark等进行学习。", null]}
{"1464940531816726528": ["分析温度和催化剂对乙醇转化率和 C4 烯烃选择性的影响，利用三次Heimite 插值模型分析乙醇转化率和 C4 烯烃选择性大小的变化以及BP神经网络预测最优的 C4 烯烃收率等。", "1.项目简介：基于包含良性和恶性乳腺癌肿瘤的显微活检图像数据集，通过图像识别，图像增强，训练 CNN 神经网络模型，应用该模型实现对乳腺癌组织病理图像的分类，模型效果正确率达到 78%。\n2.读取图像数据，通过图像旋转增加图片数量改变样本不均衡问题，对图像数据大小标准化、灰度化、归一化，划分数据集，构建 CNN 神经网络，调参，训练模型，模型检验。", "1. 基于 requests 库、Xpath、Selenium 库等的网络爬虫；\n2. 基于决策树、关联规则、聚类模型等的机器学习；\n3. 基于 tensorflow 框架的 CNN、RNN、LSTM、GAN 等神经网络模型。", "简历"]}
{"1463081637842649088": ["在本次项目中本人担任的是队员，主要是负责一部分建模和整篇论文编写这两个模块，在本次项目中，寻找更优模型来预测以及更好的制备条件来提高乙醇制备C4烯烃效率，本次比赛的重点在于构建模型以及对论文的编写陈述，三个人合作在3天之内完成一篇较完整且格式正确的论文。", "此次培训，主要是学习python这门编程语言，分为两个学习阶段：\n第一阶段：培训python语言（包括数据可视化、网络爬虫、机器学习算法、tensorflow、自然语言处理等） \n第二阶段：培训MySQL数据库项目的实战 。\n通过这门课程，我加深了对python的理解，也获得了利用python语言完成一些项目的实践经验，能够熟练地运用SQL数据库查询语言，同时，也经常撰写实验报告，对于办公软件Excel、PPT、Word也能够熟练地使用，能够主动较快地捕捉到数据的变化，报告可解析性较强。", "部分细节在简历上有提及"]}
{"1467791233622605824": ["1. 学习掌握java程序设计，Linux操作系统，SQL基础重点掌握Hadoop，hive, Zookeeper，HBase，Scala\n2. 运用Spark大数据技术与应用，Flume数据采集，Kafka大数据流处理"]}






自然语言处理,计算机视觉,BP神经网络,数据可视化,文本挖掘,opencv

自然语言处理:自然语言
MySQL:Mysql,MYSQ,SQL,Sql,sql
数据库:数据仓库
Python:python,python3,Python3,pandas,Pandas,numpy,Numpy,Matplotlib
lstm:Lstm,LSTM,循环神经网络
机器学习:支持向量机,决策树,逻辑回归,线性回归,Kmeans
深度学习:RNN,CNN,BP,神经网络
办公软件:Excel,PPT,Word,excel,ppt,word